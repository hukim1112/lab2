{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "layers = tf.contrib.layers\n",
    "from tensorflow.python.ops import variable_scope\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.framework.python.ops import variables as contrib_variables_lib\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import gradients_impl\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.ops import variable_scope\n",
    "ds = tf.contrib.distributions\n",
    "from tensorflow.python.ops.losses import losses\n",
    "from tensorflow.python.ops.losses import util\n",
    "from tensorflow.python.summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import losses_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_penalty(\n",
    "    real_data,\n",
    "    generated_data,\n",
    "    dis_scope,\n",
    "    epsilon=1e-10,\n",
    "    weights=1.0,\n",
    "    scope=None,\n",
    "    loss_collection=ops.GraphKeys.LOSSES,\n",
    "    reduction=losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
    "    add_summaries=False):\n",
    "\n",
    "  real_data = ops.convert_to_tensor(real_data)\n",
    "  generated_data = ops.convert_to_tensor(generated_data)\n",
    "  if real_data.shape.ndims is None:\n",
    "    raise ValueError('`real_data` can\\'t have unknown rank.')\n",
    "  if generated_data.shape.ndims is None:\n",
    "    raise ValueError('`generated_data` can\\'t have unknown rank.')\n",
    "\n",
    "  differences = generated_data - real_data\n",
    "  batch_size = differences.shape[0].value or array_ops.shape(differences)[0]\n",
    "  alpha_shape = [batch_size] + [1] * (differences.shape.ndims - 1)\n",
    "  alpha = random_ops.random_uniform(shape=alpha_shape)\n",
    "  interpolates = real_data + (alpha * differences)\n",
    "\n",
    "  # Reuse variables if a discriminator scope already exists.\n",
    "  reuse = False if dis_scope.name is None else True\n",
    "  with variable_scope.variable_scope(dis_scope.name, reuse=reuse):\n",
    "    disc_interpolates = discriminator(interpolates)\n",
    "    \n",
    "  gradients = gradients_impl.gradients(disc_interpolates, interpolates)[0]\n",
    "  gradient_squares = math_ops.reduce_sum(\n",
    "      math_ops.square(gradients), axis=list(range(1, gradients.shape.ndims)))\n",
    "  # Propagate shape information, if possible.\n",
    "  if isinstance(batch_size, int):\n",
    "    gradient_squares.set_shape([\n",
    "        batch_size] + gradient_squares.shape.as_list()[1:])\n",
    "  # For numerical stability, add epsilon to the sum before taking the square\n",
    "  # root. Note tf.norm does not add epsilon.\n",
    "  slopes = math_ops.sqrt(gradient_squares + epsilon)\n",
    "  penalties = math_ops.square(slopes - 1.0)\n",
    "  penalty = losses.compute_weighted_loss(penalties, weights, scope=scope)\n",
    "\n",
    "  return penalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X+QXWWd5/H3J00HGy2nE8kiaRKCDhN/FGOid4FZqsYRkaBbkoiIiVIGhc3q6mztqilDkRJkdImmlJmptdSIKAobkKhtLLUiEFirGJKhU01oghMJqCFXlAwQqmbojaHz3T/uueH0zf3Vfc+9fX98XlVdfc9znnP7y+nmfvOc55ciAjMzs6JZMx2AmZm1FycGMzObxInBzMwmcWIwM7NJnBjMzGwSJwYzM5vEicHMzCZxYjAzs0mcGMzMbJITZjqA6Tj55JNj0aJFMx2GmVlH2bVr179GxLxa9ToyMSxatIiRkZGZDsPMrKNI+l099fwoyczMJnFiMDOzSZwYzMxskkwSg6SbJT0t6ZEK5yXpHyXtk/SwpDenzq2W9FjytTqLeMzMbPqyajF8B7ioyvl3AmcmX2uArwFImgtcC5wDnA1cK2lORjGZmdk0ZJIYIuKXwLNVqiwHvhsFO4BBSacCy4C7IuLZiHgOuIvqCcbMzJqsVX0MQ8CTqeMDSVmlcjMzmyEdM49B0hoKj6FYuHDhDEdjZtZ864fHuG3HfoobML98dh9feM9ZrFja3H8/t6rFkAcWpI5PS8oqlR8nIjZFRC4icvPm1Zy4Z2bW0dYPj3FrKikA/PufJvjUnbsZHi37MZmZViWGrcCHktFJ5wLPR8RTwDbgQklzkk7nC5MyM7OeNDyaZ8nnfsGtO/aXPT9xNNi4bW9TY8jkUZKkzcDfACdLOkBhpFE/QER8HfgZ8C5gH/AC8OHk3LOS/g54MHmr6yOiWie2mVnXKrYSavn9ofGmxpFJYoiIVTXOB/DxCuduBm7OIg4zs041PJrntjqSAsD8wYGmxuKZz2ZmbWDjtr2T+hMq6Zsl1i5b3NRYnBjMzNpAPY+HXj67jy+/701NH5XUMcNVzcy62fzBAfIVkkN/n9h4afMTQpFbDGZmbWDtssUM9PcdV/7y2X0tTQrgFoOZWVsofvBv3LaX3x8aZ/7gAGuXLW5pQihyYjAzaxMrlg7NSCIo5cRgZtYkw6P5tmgBTJUTg5lZxoZH83zuJ3t47oUjx8ryh8a5+odjAG2fHNz5bGaWofXDY/zPOx6alBSKxo9MNH05iyy4xWBmloHh0TzXbd3DofHjE0Jas5ezyIITg5lZA+pNCEXNXs4iC04MZmbTNDya5+ofjjF+ZKKu+gP9fU1fziIL7mMwM5umjdv21p0UBgf6ueGS5m+ykwW3GMzMpqme/gIBHzx3IZ9fcVbzA8qIE4OZ2TRVW98IYM5J/Vz77jd2RCshzYnBzKyKapPU1i5bXLaPoVMTQlFWO7hdBPwD0AfcFBEbSs7fCLwtOTwJ+A8RMZicmwDGknP7I+LiLGIyM2tUaedy6SS1dlrfKEsqbK7WwBtIfcCvgXcAByhs07kqIh6tUP9vgaUR8ZHk+N8i4hVT+Zm5XC5GRkYaitvMrJbzNmwv+6hoaHCA+9edPwMRNUbSrojI1aqXxaiks4F9EfFERPwJuB1YXqX+KmBzBj/XzKypKnUud8IktUZk8ShpCHgydXwAOKdcRUmnA2cA21PFL5M0ArwIbIiI4QxiMjObknJ9CZU6lzthklojWj2PYSWwJSLSPTWnJ02bDwB/L+m15S6UtEbSiKSRgwcPtiJWM+sRxb6E/KFxgpf6Et72unnHbZ7TKZPUGpFFYsgDC1LHpyVl5ayk5DFSROST708A9wFLy10YEZsiIhcRuXnz5jUas5nZMeUmqo0fmeDefznIDZecxdDgAKLQt9Apk9QakcWjpAeBMyWdQSEhrKTwr/9JJL0OmAM8kCqbA7wQEYclnQycB3wpg5jMzCqayoJ37bJ5Tis1nBgi4kVJnwC2URiuenNE7JF0PTASEVuTqiuB22PyMKjXA9+QdJRC62VDpdFMZmZZGB7Ns/bO3Rw5WntEZrf3JVSSyTyGiPgZ8LOSss+WHF9X5rp/AjpnnriZdbyN2/bWlRR6oS+hEs98NrOeUmuoqaBrJqpNlxODmfWUausbderEtax52W0z6ylrly2mf5aOK+/vU88+OirlFoOZdZVqi94Bx16nRyV1+qJ3WXNiMLOuUWvRu6JeHII6FX6UZGZdo9JEtY3b9s5QRJ3JicHMukavLnqXNScGM+salSak9epEtelyYjCzjjM8mue8Dds5Y91POW/DdoZHC8uzrV22uCcXvcuaO5/NrKPU08HcbTuqtZoTg5l1hOIw1HKT04odzMXRRk4EjXFiMLO2NpWVUC0bTgxm1rZKHxtV4w7m7Ljz2czaVrl5CeW4gzlbbjGYWduq5/HQkDuYM+fEYGZtq9pKqAP9fT2xzeZMcGIwsxm1fniMzTufZCKCPolV5yzg8ysK+3etXba4bB+DF71rrkz6GCRdJGmvpH2S1pU5f4Wkg5IeSr6uSp1bLemx5Gt1FvGYWWf44Dcf4NYd+5lIdvydiODWHftZP/zSvIQbLjmLocEBROGx0d+/fwmjn73QSaGJNHkL5mm8gdQH/Bp4B3AAeBBYld67WdIVQC4iPlFy7VxgBMgBAewC3hIRz1X7mblcLkZGRhqK28xm1vBonv9xx0Nlz/VJPH7Du1ocUfeTtCsicrXqZdFiOBvYFxFPRMSfgNuB5XVeuwy4KyKeTZLBXcBFGcRkZm2u2oqnEw3+g9Uak0ViGAKeTB0fSMpKvVfSw5K2SFowxWuRtEbSiKSRgwcPZhC2mc2kaiOO+nT8DmvWOq2ax/ATYFFE/CWFVsEtU32DiNgUEbmIyM2bNy/zAM2sOSoteFdtQtqqcxZUPGfNl0ViyAPp3+JpSdkxEfFMRBxODm8C3lLvtWbWuYozl/OHxgleWvBueDRfdiVUgPNeO/fYqCSbGVkkhgeBMyWdIWk2sBLYmq4g6dTU4cXAr5LX24ALJc2RNAe4MCkzsy5QbUe1SiOObvsvfzUzwdoxDc9jiIgXJX2Cwgd6H3BzROyRdD0wEhFbgf8u6WLgReBZ4Irk2mcl/R2F5AJwfUQ822hMZjZz0vMSKin2L3gl1PbU8HDVmeDhqmbtaf3wGLfu2F+z3tDgAPevO78FEVlaK4ermpkBsHnnkzXreMG79uclMcxs2oqb5xR3S6v2+EjgHdU6hBODmU1LuS02K/FM5s7iR0lmNi317pUAnpfQadxiMLO61TPiCAothHKrpVpncGIws7p4xFHvcGIws4rWD49x28791Duq3SOOuoMTg5mVVW8LATziqNs4MZjZJMUhqNVGGaV5xFH3cWIws2NKh6DWwyOOuo8Tg5kBhaTwqe/vrnuTHI846l5ODGY9LP3YSBT2161lluArly1xX0IXc2Iw61Glj43qSQon9c/if13yl04KXc6JwaxH1TtzeaC/jxsuOcvJoIc4MZj1kPSid/W0EPokJ4Ue5MRg1iOmOuLILYXelUlikHQR8A8UdnC7KSI2lJz/JHAVhR3cDgIfiYjfJecmgLGk6v6IuDiLmMysYHg0z+d+sofnXjhSs26xA3rIk9V6WsOJQVIf8FXgHcAB4EFJWyPi0VS1USAXES9I+hjwJeD9ybnxiFjSaBxmdrzh0Txrt+zmyET1B0eeuWxpWbQYzgb2RcQTAJJuB5YDxxJDRNybqr8DuDyDn2tmVdQ7L8GL3lmpLPZjGALS+/kdSMoquRL4eer4ZZJGJO2QtCKDeMx6XrE/oVZS8KJ3Vk5LO58lXQ7kgLemik+PiLyk1wDbJY1FxONlrl0DrAFYuHBhS+I161T1DEX1iCOrJIsWQx5IL5ZyWlI2iaQLgGuAiyPicLE8IvLJ9yeA+4Cl5X5IRGyKiFxE5ObNm5dB2Gbd6/c1FsDrnyW+fNmbnBSsrCwSw4PAmZLOkDQbWAlsTVeQtBT4BoWk8HSqfI6kE5PXJwPnkeqbMLPpmT84UPHc4EA/G9/npGCVNfwoKSJelPQJYBuF4ao3R8QeSdcDIxGxFdgIvAK4UxK8NCz19cA3JB2lkKQ2lIxmMrMK0pPVSkcUrV22+Lg5C56XYPVS1Ls1UxvJ5XIxMjIy02GYzZhyk9VKP/irJQ7rTZJ2RUSuVj3PfDbrQOU6l8ePTLBx295jH/4rlg45Edi0ODGYdYD1w2Ns3vkkExH0SRWHodbqdDarhxODWRsrPDJ6mPEjR4+VVZubUK3T2axeWYxKMrMmeKkf4WjtyniymmXHicGsTdUzSW1ocAAl3z3iyLLiR0lmbapWf0Gf5DWOrCncYjBrU7X6C1ads6DqebPpcmIwa1Nrly1moL/vuPJZgsvPXcjnV5w1A1FZL/CjJLM2Vewv8CQ1azUnBrM25klqNhP8KMnMzCZxi8GsyYZH81zzozH+/U+FoacCPug+AmtjTgxmTTQ8mudTd+5m4uhLs5UDuHXHfgAnB2tLfpRk1kQbt+2dlBTSNu98smy52Uxzi8EsY+nlrqstal9rP2azmeLEYJahcvskVNJX2LTKrO04MZhlZP3w2LG+g3p45rK1q0z6GCRdJGmvpH2S1pU5f6KkO5LzOyUtSp27OinfK2lZFvGYtdpUkoLwzGVrbw23GCT1AV8F3gEcAB6UtLVk7+Yrgeci4s8lrQS+CLxf0huAlcAbgfnA3ZL+IiJqt8PNZli9fQlQWP3UC95Zp8iixXA2sC8inoiIPwG3A8tL6iwHbklebwHeLklJ+e0RcTgifgPsS97PrK0V+xLydSQF75NgnSaLxDAEpMfdHUjKytaJiBeB54FX1XktAJLWSBqRNHLw4MEMwjabvnr2SijyPgnWaTpmHkNEbIqIXETk5s2bN9PhWI+rd2/ly89d6KRgHSeLUUl5ID284rSkrFydA5JOAP4MeKbOa81mVLovobjC6fzBAfJVkkOfxKpzFriD2TpSFonhQeBMSWdQ+FBfCXygpM5WYDXwAHApsD0iQtJW4P9I+gqFzuczgX/OICazTJTOS8gfGufqH47x3rcM8YNd+UmPkwb6+/zYyLpCw4khIl6U9AlgG9AH3BwReyRdD4xExFbgW8D3JO0DnqWQPEjqfR94FHgR+LhHJFk7KLYSyrUKxo9McO+/HOSGS87yXgnWlRQdOC0/l8vFyMjITIdhXWr98Bi37dhfdbSRgN9s+M+tCsksE5J2RUSuVr2O6Xw2a4Xh0XzNpAC192M262ReEsN6XrpzeZbkeQnW85wYrKeVdi7XWvF0yH0J1gOcGKyn1TtRTcCN71/ihGA9wX0M1tPqmahW3IrTScF6hVsM1tMqTVTrkzga4WGo1pOcGKwnlJu9vGLpEGuXLT5uYx1PVLNe58RgXa/S7GXg2Ie/J6qZvcSJwbpS6RDU0tFG40cm2LhtLyuWDh37MrMCJwbrOqW7qVUaglrvCqlmvcaJwbrG8Giez/1kD8+9cKSu+p69bFaeE4N1hdJ+hFo8e9msMicG62jVVkEtR+AOZrManBisY021lTA40M9D117Y5KjMOp9nPlvHmsq+y7OA6y5+Y3MDMusSbjFYR0kPQ613J5HBgX6uu/iNfnRkVqeGEoOkucAdwCLgt8BlEfFcSZ0lwNeAVwITwBci4o7k3HeAtwLPJ9WviIiHGonJutdUHh15FVSz6Wu0xbAOuCciNkhalxx/pqTOC8CHIuIxSfOBXZK2RcSh5PzaiNjSYBzWA+p5dOTlLMwa12gfw3LgluT1LcCK0goR8euIeCx5/XvgaWBegz/XelC1CWmi0EpwUjBrXKMthlMi4qnk9R+AU6pVlnQ2MBt4PFX8BUmfBe4B1kXE4QZjsi5VaSXUocEB7l93/gxEZNadarYYJN0t6ZEyX8vT9SIioHJ/oKRTge8BH46Io0nx1cDrgP8IzOX4x1Dp69dIGpE0cvDgwdr/ZdZ11i5bzEB/36QyT1Qzy17NFkNEXFDpnKQ/Sjo1Ip5KPvifrlDvlcBPgWsiYkfqvYutjcOSvg18ukocm4BNALlcrt4BKdZB1g+PsXnnk0xE0Cex6pwFfH7FWcfOeyVUs9Zo9FHSVmA1sCH5/uPSCpJmAz8CvlvayZxKKqLQP/FIg/FYhyq38F3xuDQ5OBGYNVejnc8bgHdIegy4IDlGUk7STUmdy4C/Bq6Q9FDytSQ5d5ukMWAMOBn4fIPxWIfavPPJKZWbWfM01GKIiGeAt5cpHwGuSl7fCtxa4Xr3GBpQeWnsSuVm1jxeEsPaQp80pXIzax4viWEtUbpXQukyFavOWTCpj6Fo1TkLWhqnmTkxWJMNj+a5buseDo1P3jzn0PgR1t65Gyh0KBc7mKuNSjKz1lB04DPcXC4XIyMjMx2G1bB+eIzbduyvutidJ6eZtY6kXRGRq1XPfQzWFMOj+ZpJAbzvslk7cmKwpti4bW9dy2J732Wz9uM+BstEpb6EavpnyctZmLUhJwZr2Ae/+QD3P/7slK7x5jlm7cuJwRqyfnis7qQg4IPnLvRII7M258RgDalnyQqBF7wz6yBODDZlU9l32cNRzTqPE4NNyVT2Xe7vc+eyWSfycFWbknr2XQY48YRZbLz0TX50ZNaB3GKwqko3z6m12qmXsjDrfE4MVlHpMNRqScF9CWbdw4nBjjPVyWred9msuzTUxyBprqS7JD2WfJ9Tod5Eave2ranyMyTtlLRP0h3JNqA2g4qdy7WSwtDgAEq+33DJWe5LMOsijbYY1gH3RMQGSeuS48+UqTceEUvKlH8RuDEibpf0deBK4GsNxmQNqKdzuU/yYyOzLtboqKTlwC3J61uAFfVeKEnA+cCW6VxvzVHPaqfePMesuzXaYjglIp5KXv8BOKVCvZdJGgFeBDZExDDwKuBQRLyY1DkA+HlEi5SONiqOJJo/OEC+SnI477VzPeLIrMvVTAyS7gZeXebUNemDiAhJlYatnB4ReUmvAbZLGgOen0qgktYAawAWLlw4lUutxPrhsUnbaE5EHDteu2xx2Qlsc07q59p3e9E7s15QMzFExAWVzkn6o6RTI+IpSacCT1d4j3zy/QlJ9wFLgR8Ag5JOSFoNpwH5KnFsAjZBYQe3WnHb8dKthHI273zyWGuguOSF1zgy6z2NPkraCqwGNiTff1xaIRmp9EJEHJZ0MnAe8KWkhXEvcClwe6XrLRulrYRyigljxdIhJwKzHtZo5/MG4B2SHgMuSI6RlJN0U1Ln9cCIpN3AvRT6GB5Nzn0G+KSkfRT6HL7VYDxWRj1JAQqjjczMGmoxRMQzwNvLlI8AVyWv/wko21sZEU8AZzcSg5U3PJrncz/Zw3Mv1L+jmkcbmRl45nNXGh7Ns3bLbo5M1NcV4/WNzCzNiaELbdy2t+6kcLl3VDOzEl52uwvVM0kNnBTMrDwnhi40f3CgZh0nBTOrxImhgw2P5jlvw3bOWPdTztuwneHRwjSQtcsW099XfoTRLDkpmFl17mPoUKVbbOYPjXP1D8cAjs1BSI9KGhzo57qLPXPZzGpzYuhAw6N5PvX93cfNYB4/MsHGbXuPTVBzEjCz6fCjpA5TbClUWtai3o5nM7NK3GLoAMOj+WNrF82qse9yPR3PZmbVODG0udK+hGpJwVtsmlkW/CipzdWzoxoUZi97i00zy4ITQ5urp89goL+PL1/2JicFM8uEE0Obq9Rn0CchYGhwwC0FM8uU+xjaQLpzuXRjnHI7qg309zkZmFnTODHMsOHRPGvv3M2Ro4VO5fyhcdbeuRuYvGGOd1Qzs1ZRVBnl0q5yuVyMjIzMdBiZWPK5X3Bo/Pg9EwYH+nno2gtnICIz61aSdkVErlY99zHMsHJJoVq5mVmzNfQoSdJc4A5gEfBb4LKIeK6kztuAG1NFrwNWRsSwpO8AbwWeT85dEREPNRJTuyvtTzAzazeN9jGsA+6JiA2S1iXHn0lXiIh7gSVwLJHsA36RqrI2IrY0GEfbK7fVZr7KUNQ5J/W3Iiwzs+M0+ihpOXBL8voWYEWN+pcCP4+IFxr8uR2lOHu53v2X+/vEte9+Y5OjMjMrr9EWwykR8VTy+g/AKTXqrwS+UlL2BUmfBe4B1kXE4XIXSloDrAFYuHDh9CNuofXDY2ze+WTVZSyKhgYHPOrIzNpCzVFJku4GXl3m1DXALRExmKr7XETMqfA+pwIPA/Mj4kiq7A/AbGAT8HhEXF8r6E4YlbR+eIxbd+yvq+7Q4AD3rzu/yRGZWa+rd1RSzRZDRFxQ5Yf8UdKpEfFU8iH/dJW3ugz4UTEpJO9dbG0clvRt4NO14mlnU2khFHnhOzNrN432MWwFVievVwM/rlJ3FbA5XZAkEySJQv/EIw3GM2M++M0HuHXH/iklhcGBfs9gNrO202gfwwbg+5KuBH5HoVWApBzw0Yi4KjleBCwA/m/J9bdJmgcIeAj4aIPxzIjh0Tz3P/5s3fWH3I9gZm2socQQEc8Aby9TPgJclTr+LXDcp2BEdMWD9Y3b9tZd9/JzF/L5FWc1MRozs8Z4raQM1LM0dp/EqnMWOCmYWdtzYsjA/MGBipPV3EIws07jtZIysHbZYgb6+44rP++1c50UzKzjuMVQh2r7JQBeGtvMuooTQw3F5SyKG+XkD41z9Q/HAI5LDk4EZtYNnBgqKLYSyvUdjB+ZYOO2vU4EZtaVnBjKKG0llFPPSCQzs07kxJBI9yPMkmrOYPZeCmbWrZwYOL6FUCspeH0jM+tmTgwURhNVe2yU5uUszKzbOTFQX3/BQH+fF7wzs57Qk4mhdF7Cnw30c2j8+N3V+iSORnhegpn1lJ5KDJX2Xe7vE/2zxJGjL/UtuIVgZr2qZxJDtSGoRyaCOSf1c9LsEzxz2cx6Xs8khlodzIdeOMLoZy9sYURmZu2pZxbRq9XB7HkJZmYFDSUGSe+TtEfS0WTXtkr1LpK0V9I+SetS5WdI2pmU3yFpdiPxVFPtg9/zEszMXtJoi+ER4BLgl5UqSOoDvgq8E3gDsErSG5LTXwRujIg/B54DrmwwnooqLY3tfZfNzCZrdGvPXwFIqlbtbGBfRDyR1L0dWC7pV8D5wAeSercA1wFfaySmSrw0tplZfVrR+TwEPJk6PgCcA7wKOBQRL6bKm/op7aWxzcxqq5kYJN0NvLrMqWsi4sfZh1QxjjXAGoCFCxe26seamfWcmokhIi5o8GfkgQWp49OSsmeAQUknJK2GYnmlODYBmwByuVz1Ve7MzGzaWjFc9UHgzGQE0mxgJbA1IgK4F7g0qbcaaFkLxMzMymt0uOp7JB0A/gr4qaRtSfl8ST8DSFoDnwC2Ab8Cvh8Re5K3+AzwSUn7KPQ5fKuReMzMrHGKGnsPtKNcLhcjIyMzHYaZWUeRtCsiKs45K+qZmc9mZlafjmwxSDoI/K5KlZOBf21RONPRzvE5tulp59igveNzbNM31fhOj4h5tSp1ZGKoRdJIPc2lmdLO8Tm26Wnn2KC943Ns09es+PwoyczMJnFiMDOzSbo1MWya6QBqaOf4HNv0tHNs0N7xObbpa0p8XdnHYGZm09etLQYzM5umjk0M7bxJkKS5ku6S9FjyfU6ZOm+T9FDq6/9JWpGc+46k36TOLckqtnrjS+pNpGLYmiqf6Xu3RNIDye//YUnvT53L/N5V+htKnT8xuQ/7kvuyKHXu6qR8r6RljcYyjdg+KenR5D7dI+n01Lmyv98Wx3eFpIOpOK5KnVud/B08Jmn1DMR2YyquX0s6lDrX1Hsn6WZJT0t6pMJ5SfrHJPaHJb05da7x+xYRHfkFvB5YDNwH5CrU6QMeB14DzAZ2A29Izn0fWJm8/jrwsQxj+xKwLnm9DvhijfpzgWeBk5Lj7wCXNvHe1RUf8G8Vymf03gF/AZyZvJ4PPAUMNuPeVfsbStX5b8DXk9crgTuS129I6p8InJG8T1+LY3tb6u/qY8XYqv1+WxzfFcD/LnPtXOCJ5Puc5PWcVsZWUv9vgZtbeO/+Gngz8EiF8+8Cfg4IOBfYmeV969gWQ0T8KiL21qh2bJOgiPgTUNwkSBQ2CdqS1LsFWJFheMuT96z3vS8Ffh4RL2QYQzVTje+Ydrh3EfHriHgsef174Gmg5qSdaSr7N1Ql5i3A25P7tBy4PSIOR8RvgH3J+7Ustoi4N/V3tYPCKsatUs+9q2QZcFdEPBsRzwF3ARfNYGyrgM0Z/vyqIuKXFP6xWMly4LtRsIPCStWnktF969jEUKdymwQN0fxNgk6JiKeS138ATqlRfyXH/9F9IWki3ijpxAxjm0p8L5M0ImlH8TEXbXbvJJ1N4V98j6eKs7x3lf6GytZJ7svzFO5TPdc2O7a0Kyn8K7Oo3O83S/XG997k97VFUnGJ/ra5d8njtzOA7aniZt+7WirFn8l9a8UObtOmNtkkqJxqsaUPIiIkVRz6lWT5syisPlt0NYUPxdkUhqN9Brh+BuI7PSLykl4DbJc0RuFDryEZ37vvAasj4mhS3PC960aSLgdywFtTxcf9fiPi8fLv0DQ/ATZHxGFJ/5VCy+v8FsdQy0pgS0RMpMra4d41TVsnhmiTTYKmGpukP0o6NSKeSj68nq7yVpcBP4qII6n3Lv6L+bCkbwOfnkpsWcUXEfnk+xOS7gOWAj+gDe6dpFcCP6Xwj4Qdqfdu+N6VqPQ3VK7OAUknAH9G4W+snmubHRuSLqCQdN8aEYeL5RV+v1l+uNWMLyKeSR3eRKGPqXjt35Rce18rY0tZCXw8XdCCe1dLpfgzuW/d/ihppjYJ2pq8Zz3vfdyzy+QDsfg8fwVQdmRCM+OTNKf4GEbSycB5wKPtcO+S3+WPKDxj3VJyLut7V/ZvqErMlwLbk/u0FVipwqilM4AzgX9uMJ4pxSZpKfAN4OKIeDpVXvb3m2Fs9cZ3aurwYgp7tkChBX1hEucc4EImt6qbHlsS3+sodOI+kCprxb2rZSvwoWR00rnA88k/irK5b83sWW/mF/AeCs/PDgN/BLYl5fOBn6XqvQv4NYVsfk2q/DUU/ifdB9wJnJhhbK8C7gEeA+4G5iblOeCmVL1FFDL8rJKaPPSeAAAAzUlEQVTrtwNjFD7UbgVekfG9qxkf8J+SGHYn369sl3sHXA4cAR5KfS1p1r0r9zdE4fHUxcnrlyX3YV9yX16Tuvaa5Lq9wDub8P9BrdjuTv7/KN6nrbV+vy2O7wZgTxLHvcDrUtd+JLmn+4APtzq25Pg6YEPJdU2/dxT+sfhU8nd+gEL/0EeBjybnBXw1iX2M1MjMLO6bZz6bmdkk3f4oyczMpsiJwczMJnFiMDOzSZwYzMxsEicGMzObxInBzMwmcWIwM7NJnBjMzGyS/w8XoLyhBjcPFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        random_noise = tf.random_uniform([100, 1])\n",
    "        random_noise = (random_noise - 0.5)*2\n",
    "        \n",
    "        a_y = tf.constant([[1, 1]], tf.float32) #signal direction\n",
    "        real_data = tf.multiply(a_y, random_noise)\n",
    "        real_data = sess.run(real_data)\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.scatter(real_data[:, 0], real_data[:, 1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = lambda net: tf.nn.leaky_relu(net, alpha=0.01)\n",
    "def generator(input_noise):\n",
    "    gen_data = layers.fully_connected(input_noise, 2, activation_fn=None)\n",
    "    return gen_data\n",
    "\n",
    "def discriminator(data):\n",
    "    logits = layers.fully_connected(data, 1, activation_fn=None)\n",
    "    D_prob = tf.nn.sigmoid(logits)\n",
    "    return D_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7303ba7951c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrandom_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrandom_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrandom_noise\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#signal direction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    random_noise = tf.random_uniform([1000, 1])\n",
    "    random_noise = (random_noise - 0.5)*2\n",
    "        \n",
    "    a_y = tf.constant([[2, 1]], tf.float32) #signal direction\n",
    "    real_data = tf.multiply(a_y, random_noise)\n",
    "    \n",
    "    with variable_scope.variable_scope('generator') as gen_scope:\n",
    "        gen_data = generator(random_noise)\n",
    "        \n",
    "    with variable_scope.variable_scope('discriminator') as dis_scope:\n",
    "        logits_real = discriminator(real_data)\n",
    "    with variable_scope.variable_scope('discriminator', reuse=True):\n",
    "        logits_gen = discriminator(gen_data)\n",
    "        \n",
    "    dis_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=dis_scope.name)\n",
    "    gen_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=gen_scope.name)\n",
    "        \n",
    "#     epsilon = 0.0006\n",
    "#     D_loss = -tf.reduce_mean(tf.log(logits_real + epsilon) + tf.log(1. - logits_gen + epsilon))\n",
    "#     G_loss = -tf.reduce_mean(tf.log(logits_gen + epsilon))\n",
    "\n",
    "    D_loss = losses_fn.wasserstein_discriminator_loss(logits_real, logits_gen)\n",
    "    G_loss = losses_fn.wasserstein_generator_loss(logits_gen)\n",
    "    wasserstein_penalty_loss = wasserstein_penalty(real_data, gen_data, dis_scope)\n",
    "        \n",
    "    D_solver = tf.train.AdamOptimizer().minimize(D_loss+wasserstein_penalty_loss, var_list=dis_var)\n",
    "    G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=gen_var)\n",
    "    \n",
    "    initializer = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(initializer)\n",
    "        test_real = sess.run(real_data)\n",
    "        test_gen = sess.run(gen_data)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(221)\n",
    "        ax1.scatter(test_real[:, 0], test_real[:, 1], c='r')\n",
    "        ax1.scatter(test_gen[:, 0], test_gen[:, 1], c='b')\n",
    "        \n",
    "        for i in range(30001):\n",
    "            for _ in range(3):\n",
    "                sess.run(D_solver)\n",
    "            for _ in range(3):\n",
    "                sess.run(G_solver)\n",
    "        \n",
    "            if i == 10000:\n",
    "                test_real = sess.run(real_data)\n",
    "                test_gen = sess.run(gen_data)\n",
    "\n",
    "\n",
    "                with variable_scope.variable_scope('discriminator', reuse=True):\n",
    "                    weight1 = tf.get_variable('fully_connected/weights')\n",
    "                    bias2 = tf.get_variable('fully_connected/biases')\n",
    "                    w = sess.run(weight1)\n",
    "                    b = sess.run(bias2)\n",
    "                    print(w, b)\n",
    "                    p1 = (0, -b/w[1])\n",
    "                    p2 = (-b/w[0], 0)        \n",
    "\n",
    "\n",
    "                fig = plt.figure()\n",
    "                ax1 = fig.add_subplot(222)\n",
    "                ax1.scatter(test_real[:, 0], test_real[:, 1], c='r')\n",
    "                ax1.scatter(test_gen[:, 0], test_gen[:, 1], c='b')\n",
    "                ax1.plot(np.array([0]), np.array([0]), c=(1,0,1))\n",
    "                coefficients = np.polyfit([p1[0], p2[0]], [p1[1], p2[1]], 1) \n",
    "                polynomial = np.poly1d(coefficients)\n",
    "                x_axis = np.linspace(-2, 2)\n",
    "                y_axis = polynomial(x_axis)\n",
    "                ax1.plot(x_axis, y_axis, c='g')\n",
    "                ax1.scatter(np.array([0]), np.array([0]), c=(0,0,0), s=25)\n",
    "                print(sess.run(logits_real).min(), sess.run(logits_real).max())\n",
    "                print(sess.run(logits_gen).min(), sess.run(logits_gen).max())\n",
    "            if i == 20000:\n",
    "                test_real = sess.run(real_data)\n",
    "                test_gen = sess.run(gen_data)\n",
    "\n",
    "\n",
    "                with variable_scope.variable_scope('discriminator', reuse=True):\n",
    "                    weight1 = tf.get_variable('fully_connected/weights')\n",
    "                    bias2 = tf.get_variable('fully_connected/biases')\n",
    "                    w = sess.run(weight1)\n",
    "                    b = sess.run(bias2)\n",
    "                    print(w, b)\n",
    "                    p1 = (0, -b/w[1])\n",
    "                    p2 = (-b/w[0], 0)        \n",
    "\n",
    "\n",
    "                fig = plt.figure()\n",
    "                ax1 = fig.add_subplot(223)\n",
    "                ax1.scatter(test_real[:, 0], test_real[:, 1], c='r')\n",
    "                ax1.scatter(test_gen[:, 0], test_gen[:, 1], c='b')\n",
    "                coefficients = np.polyfit([p1[0], p2[0]], [p1[1], p2[1]], 1) \n",
    "                polynomial = np.poly1d(coefficients)\n",
    "                x_axis = np.linspace(-2, 2)\n",
    "                y_axis = polynomial(x_axis)\n",
    "                ax1.plot(x_axis, y_axis, c='g')\n",
    "                \n",
    "                ax1.scatter(np.array([0]), np.array([0]), c=(0,0,0), s=25)\n",
    "                print(sess.run(logits_real).min(), sess.run(logits_real).max())\n",
    "                print(sess.run(logits_gen).min(), sess.run(logits_gen).max())          \n",
    "            if i == 30000:\n",
    "                test_real = sess.run(real_data)\n",
    "                test_gen = sess.run(gen_data)\n",
    "\n",
    "\n",
    "                with variable_scope.variable_scope('discriminator', reuse=True):\n",
    "                    weight1 = tf.get_variable('fully_connected/weights')\n",
    "                    bias2 = tf.get_variable('fully_connected/biases')\n",
    "                    w = sess.run(weight1)\n",
    "                    b = sess.run(bias2)\n",
    "                    print(w, b)\n",
    "                    p1 = (0, -b/w[1])\n",
    "                    p2 = (-b/w[0], 0)        \n",
    "\n",
    "\n",
    "                fig = plt.figure()\n",
    "                ax1 = fig.add_subplot(224)\n",
    "                ax1.scatter(test_real[:, 0], test_real[:, 1], c='r')\n",
    "                ax1.scatter(test_gen[:, 0], test_gen[:, 1], c='b')\n",
    "                ax1.plot(np.array([0]), np.array([0]), c=(1,0,1))\n",
    "                coefficients = np.polyfit([p1[0], p2[0]], [p1[1], p2[1]], 1) \n",
    "                polynomial = np.poly1d(coefficients)\n",
    "                x_axis = np.linspace(-2, 2)\n",
    "                y_axis = polynomial(x_axis)\n",
    "                ax1.plot(x_axis, y_axis, c='g')\n",
    "                ax1.scatter(np.array([0]), np.array([0]), c=(0,0,0), s=25)\n",
    "                print(sess.run(logits_real).min(), sess.run(logits_real).max())\n",
    "                print(sess.run(logits_gen).min(), sess.run(logits_gen).max())\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    random_noise = tf.random_uniform([1000, 1])\n",
    "    random_noise = (random_noise - 0.5)*2\n",
    "        \n",
    "    a_y = tf.constant([[1, 1]], tf.float32) #signal direction\n",
    "    real_data = tf.multiply(a_y, random_noise)\n",
    "    print(real_data.shape) # real_dataset\n",
    "        \n",
    "    with variable_scope.variable_scope('generator') as gen_scope:\n",
    "        gen_data = generator(random_noise) - tf.constant([[0, 1]], tf.float32)\n",
    "        \n",
    "    with variable_scope.variable_scope('discriminator') as dis_scope:\n",
    "        logits_real = discriminator(real_data)\n",
    "    with variable_scope.variable_scope('discriminator', reuse=True):\n",
    "        logits_gen = discriminator(gen_data)\n",
    "        \n",
    "    dis_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=dis_scope.name)\n",
    "    gen_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=gen_scope.name)\n",
    "    \n",
    "    epsilon = 0.0006\n",
    "    D_loss = -tf.reduce_mean(tf.log(logits_real + epsilon) + tf.log(1. - logits_gen + epsilon))\n",
    "    G_loss = -tf.reduce_mean(tf.log(logits_gen + epsilon))\n",
    "        \n",
    "    D_solver = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(D_loss, var_list=dis_var)\n",
    "    G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=gen_var)\n",
    "    \n",
    "    initializer = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(initializer)\n",
    "        \n",
    "        for i in range(50000):\n",
    "                            \n",
    "            sess.run(D_solver)\n",
    "            sess.run(G_solver)\n",
    "        test_real = sess.run(real_data)\n",
    "        test_gen = sess.run(gen_data)\n",
    "\n",
    "        with variable_scope.variable_scope('discriminator', reuse=True):\n",
    "            weight1 = tf.get_variable('fully_connected/weights')\n",
    "            bias2 = tf.get_variable('fully_connected/biases')\n",
    "            w = sess.run(weight1)\n",
    "            b = sess.run(bias2)\n",
    "            print('dis_weight', w, '\\n')\n",
    "            print('dis_bias', b, '\\n')\n",
    "            print('prob : ', sess.run(tf.nn.sigmoid(w[0]*0.5 + w[1]*0.5 + b)), '\\n') \n",
    "            p1 = (0, -b/w[1])\n",
    "            p2 = (-b/w[0], 0)        \n",
    "\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.scatter(test_gen[:, 0], test_gen[:, 1], c='b')\n",
    "        ax1.scatter(test_real[:, 0], test_real[:, 1], c='r')\n",
    "        coefficients = np.polyfit([p1[0], p2[0]], [p1[1], p2[1]], 1) \n",
    "        polynomial = np.poly1d(coefficients)\n",
    "        x_axis = np.linspace(-8, 3)\n",
    "        y_axis = polynomial(x_axis)\n",
    "\n",
    "        ax1.plot(x_axis, y_axis, c='g')\n",
    "        plt.show()\n",
    "                \n",
    "#\n",
    "        \n",
    "        print(sess.run(logits_real[:10]))\n",
    "        print(sess.run(logits_gen[:10]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.6p3",
   "language": "python",
   "name": "tf1.6p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
